# Capability: Enhanced Diagram Generation

## Overview

Extend diagram generation to produce richer, more informative diagrams with explicit data flow visualization, debugging metadata, real-world examples, scenario testing, and quality assurance.

## ADDED Requirements

### Requirement: Data Flow Visualization
The system SHALL generate diagrams that explicitly visualize data movement through components with animated flow indicators showing source, destination, data type, and transformation.

#### Scenario: Understanding Data Movement
When a user views a "Load Balancer" diagram, they see:
- Arrows flowing from Client → Load Balancer → Servers
- Each arrow is animated with a dashed pattern moving in direction of flow
- Arrow changes color/style to show data transformation (request → routed request)
- Step description explains: "HTTP request flows from client to load balancer, which routes it to an available server"

#### Specification
- Every `Step` includes `dataFlows` array describing movement:
  ```typescript
  dataFlow {
    fromComponent: string (component ID)
    toComponent: string (component ID)
    dataType: string (e.g., "HTTP request", "Response")
    transformation?: string (e.g., "Parsed and routed")
    isRequired: boolean (part of critical path?)
  }
  ```
- SVG includes animated flow indicators:
  - `<path data-flow="true" data-from="a" data-to="b" .../>`
  - CSS animation with `stroke-dasharray` for flowing effect
  - Color indicates data type or transformation
- Each data flow has visual path in SVG connecting the components
- Animation synchronized with step (flows happen when step is active)

### Requirement: Interactive Debugging Metadata
The system SHALL generate component metadata with multi-layer explanations (detailed explanation, inputs, outputs, failure modes, failure recovery) for deep understanding.

#### Scenario: Understanding Why Component Matters
User hovers/clicks Load Balancer component. Inspector panel shows:
- **What**: "Distributes traffic across servers"
- **How It Works**: "Uses Round-Robin algorithm to select next available server. Checks server health every 5 seconds."
- **Real-World**: "AWS ELB, Nginx, HAProxy all implement this"
- **Failure Mode**: "If load balancer fails, traffic is dropped until failover completes"
- **Inputs**: "HTTP requests from clients, Health status from servers"
- **Outputs**: "Routed HTTP request to selected server"

#### Specification
- Each `Component` includes:
  ```typescript
  detailedExplanation: string    // 2-3 sentences on HOW it works (algorithm, logic)
  inputs: string[]               // What it receives
  outputs: string[]              // What it produces
  failureMode?: string           // What breaks if this fails
  failureRecovery?: string       // How system recovers
  ```
- Content generated by AI, validated for accuracy
- Explanations target intermediate learners (assume some domain knowledge)
- Failure modes are realistic, not contradictory to diagram
- All references to other components are accurate

### Requirement: Real-World Domain Mapping
The system SHALL map abstract components to actual real-world technologies and products with documentation links for practical relevance.

#### Scenario: Connecting to Real Tools
For Load Balancer component, user sees:
- **AWS**: "Elastic Load Balancer (ELB)"
  - Link: `https://docs.aws.amazon.com/elasticloadbalancing/`
- **Kubernetes**: "Ingress Controller (Nginx)"
  - Link: `https://kubernetes.io/docs/concepts/services-networking/ingress/`
- **Self-hosted**: "HAProxy"
  - Link: `http://www.haproxy.org/`

#### Specification
- Each `Component` includes:
  ```typescript
  realWorldExamples: {
    technology: string   // "AWS", "Kubernetes", "Nginx", etc.
    name: string         // Product/service name
    link?: string        // Documentation link
  }[]
  ```
- Minimum 2-3 examples per component
- AI must NOT hallucinate examples (use well-known, real products only)
- Links must be accurate and current
- Validation checks that examples are plausible

### Requirement: Scenario-Based Learning
The system SHALL generate 3-5 "what if?" scenarios per diagram testing understanding through realistic failure, overload, and edge case simulations.

#### Scenario: Testing Understanding Through Simulation
User clicks "Test Scenario: High Traffic Load". Diagram animates:
- Load Balancer highlighted with red glow (overload state)
- Animation slows down to show bottleneck
- Queue builds up visually
- Explanation appears: "Load balancer capacity is exceeded. Requests queue up. Without auto-scaling, requests start timing out."
- Question appears: "What should happen next?"

#### Specification
- `DiagramContent` includes `scenarios` array:
  ```typescript
  scenario {
    scenarioName: string              // "High Traffic Load", "Server Failure"
    description: string               // What the scenario simulates
    impactedComponents: string[]      // Which components are affected
    visualization: {
      highlightComponents: string[]   // Show as active/important
      dimComponents: string[]         // Show as offline/inactive
      animationType: enum             // "overload" | "failure" | "slow" | "bottleneck"
    }
    lessonLearned: string            // Educational takeaway
  }
  ```
- Minimum 3-5 scenarios per diagram
- Scenarios should cover:
  - Normal operation (baseline)
  - Failure scenarios (what breaks)
  - Overload/stress scenarios (capacity limits)
  - Edge cases relevant to concept
- Each scenario is tied to real-world situations
- Visualization is clear and non-confusing

### Requirement: Learning Time Estimation
The system SHALL estimate realistic learning times for different depths (quick view, deep understanding, mastery) with difficulty ratings and prerequisite guidance.

#### Scenario: Planning Learning Session
User sees control panel:
- "Quick View: 3 minutes" - just watch animations
- "Deep Understanding: 12 minutes" - read all explanations
- "Master It: 25 minutes" - understand edge cases and test knowledge

#### Specification
- `metadata` includes `timeEstimates`:
  ```typescript
  timeEstimates {
    quickView: number              // Minutes (2-10)
    deepUnderstanding: number      // Minutes (5-30)
    masteryChallenges: number      // Minutes (10-60)
  }
  conceptDifficulty: number        // 1-10 scale
  prerequisites: string[]          // ["Basic networking", ...]
  keyInsights: string[]            // 3-5 main takeaways
  ```
- Time estimates are realistic (validated against actual user data)
- Difficulty reflects complexity of concept (not just component count)
- Prerequisites help user know if they're ready
- Key insights are memorable and capture essence of concept

### Requirement: Quality Assurance & Confidence Scoring
The system SHALL validate all diagram components before returning and include a confidence score (0-100) with generation notes explaining quality assessment.

#### Scenario: Validating Generated Quality
After generation, system includes:
- `qualityScore: 87` (out of 100)
- `generationNotes: ["High confidence", "Well-structured components", "Clear data flows"]`
- If score < 70: Flag for review before showing user

#### Specification
- `metadata` includes:
  ```typescript
  qualityScore: number             // 0-100, AI self-assessment
  generationNotes: string[]        // Explanation of score
  ```
- Validation checks (run by AI before returning):
  1. All step references exist in components
  2. All data flows reference valid components
  3. No orphaned components (unreferenced in any step)
  4. Animation timing consistent (no jarring time differences)
  5. Failure modes are realistic (not contradictory)
  6. Real-world examples are accurate/plausible
  7. Scenarios are coherent with diagram
  8. Time estimates are reasonable (2-60 min range)
  9. Prerequisites make sense (no circular dependencies)
  10. Quality score accurately reflects diagram quality
- If any validation fails: Log warning, score reduced, continues (no hard failure)
- Score calculation:
  - Start at 100
  - Deduct 5 for each validation issue
  - Deduct 10 if metadata fields missing
  - Final score = max(0, 100 - penalties)

### Requirement: Component Layering
The system SHALL tag each component with a layer ("core" or "advanced") enabling frontend to show/hide components based on user complexity preference.

#### Scenario: Showing Only Essential Components to Beginners
User has complexity toggle OFF. Sees only "core" layer components:
- Load Balancer, Server Pool, Request Queue (core)
- Hidden: Health Check, Cache, Session State, Backup (advanced)

User toggles "Show Advanced". Instantly:
- All components visible
- Advanced components show with different styling
- No re-render or API call needed

#### Specification
- Each `Component` includes:
  ```typescript
  layer: "core" | "advanced"
  ```
- SVG elements include attribute:
  ```xml
  <g data-layer="core" ...>...</g>
  <g data-layer="advanced" ...>...</g>
  ```
- AI generates:
  - Core: 5-8 essential components (explains main concept)
  - Advanced: 3-5 additional components (depth, optimization, resilience)
  - At least 50% of steps should use core components
- Frontend CSS rule:
  ```css
  [data-layer="advanced"] { display: none; }
  .show-advanced [data-layer="advanced"] { display: block; }
  ```

### Requirement: Enhanced SVG Animation Coordination
The system SHALL coordinate and stagger animations across steps for visual clarity, using delays and sequencing to show progression and data flow.

#### Scenario: Seeing Data Movement Clearly
In step showing "Request routing", animation happens in sequence:
1. Client request appears (0ms)
2. Flows from client to load balancer (0.3s, with dash animation)
3. Load balancer highlights and decides (0.3s)
4. Request flows to selected server (0.3s, dash animation)
5. Server processes (0.4s, glow/pulse effect)

Total time: ~1.3s. User sees clear progression, not confusing simultaneous animations.

#### Specification
- Each `Step` includes `animationTiming`:
  ```typescript
  animationTiming {
    duration: number             // milliseconds (100-5000)
    easing?: string              // "ease-in-out", "linear"
    delay?: number               // milliseconds (NEW)
    sequence?: string            // "parallel" | "sequential" (NEW)
  }
  ```
- SVG includes coordinated `@keyframes`:
  ```css
  /* Each animation has delay for staggering */
  [data-animation="phase1"] { animation: moveRight 0.3s ease-in-out 0ms; }
  [data-animation="phase2"] { animation: moveRight 0.3s ease-in-out 0.3s; }
  [data-animation="phase3"] { animation: moveRight 0.3s ease-in-out 0.6s; }
  ```
- Data flows use dash-offset animation:
  ```css
  [data-flow="true"] {
    stroke-dasharray: 10, 5;
    animation: flowRight 2s linear infinite;
  }
  ```
- Component state changes use opacity/filter:
  ```css
  [data-transforming="true"] {
    animation: transformState 0.8s ease-in-out forwards;
  }
  ```
- Animations are smooth (no stuttering, use GPU-accelerated properties)

## MODIFIED Requirements

### Requirement: Diagram Generation Input (Enhanced)
Genkit flow SHALL generate enhanced diagram output including all new metadata (data flows, debugging info, scenarios, time estimates, quality score) without additional input parameters.

#### Scenario: Generation Includes All Metadata
User requests "Load Balancer". System generates complete DiagramContent with:
- SVG with data flows, layer tags, animation delays
- Components with debugging metadata, real-world examples
- Steps with state snapshots and data flows
- Scenarios for testing understanding
- Time estimates and key insights
- Quality score (85/100, "High confidence")

#### Specification
- Modify `generateInteractiveDiagram` to request enhanced metadata
- Extend Genkit prompt with all new sections (see design doc)
- Validation ensures all new fields are populated (or have sensible defaults)
- Backward compatibility: Old diagrams without new fields still work
- Generation time increase: <2 seconds (acceptable overhead)

## REMOVED Requirements

None. Pure addition to existing capabilities.

## Data Validation

### Data Flow Constraints
- `fromComponent` and `toComponent` must exist in components array
- `dataType` should be concise and meaningful
- No duplicate data flows (same from/to/type)
- At least one data flow per step (except initial/final)

### Debugging Metadata Constraints
- `detailedExplanation`: 100-300 characters, non-empty
- `inputs`/`outputs`: Non-empty arrays, 1-5 items each
- `failureMode`/`failureRecovery`: 50-200 characters each, realistic
- Real-world examples: At least 2, no hallucinated products
- All references to other components are accurate

### Scenario Constraints
- Scenario name: Non-empty, descriptive (20-40 chars)
- Description: 50-150 characters
- impactedComponents: Non-empty, references valid components
- animationType: Valid enum value
- lessonLearned: 50-150 characters, educational value

### Time Estimate Constraints
- `quickView`: 2-10 minutes
- `deepUnderstanding`: 5-30 minutes
- `masteryChallenges`: 10-60 minutes
- `conceptDifficulty`: Integer 1-10
- `prerequisites`: Non-empty array
- `keyInsights`: 3-5 items

### Quality Score Constraints
- Score: Integer 0-100
- generationNotes: 2-5 items, brief explanations
- Score ≥70 indicates acceptable quality

## Cross-System Constraints

- All component references must be resolvable (validation catch)
- No circular dependencies in prerequisites
- Data flows must have logical sense (source → destination)
- Failure modes should not contradict success scenarios
- Real-world examples should be accurate (no hallucinations)
- Time estimates should be consistent across components

## Performance Targets

- Generation time: <20 seconds total (including metadata)
- Metadata size: <50KB per diagram
- Validation time: <1 second
- SVG rendering time: <2 seconds
- Animation smoothness: 60fps maintained during playback

## Success Criteria

1. **Data Flow Clarity**: 80%+ users can describe how data moves through system
2. **Debugging Value**: 75%+ users find debugging metadata helpful
3. **Real-World Connection**: 70%+ users identify relevant real-world technology
4. **Scenario Engagement**: 60%+ interact with at least one scenario
5. **Time Accuracy**: Estimated time within 20% of actual
6. **Quality Score**: Average 75+/100
7. **No Generation Failures**: 99%+ success rate (only hallucinated examples cause failures)
8. **Performance**: <20s generation time maintained

